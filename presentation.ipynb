{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5905396c",
      "metadata": {
        "id": "5905396c"
      },
      "source": [
        "# **Knowledge Representation in RAG methods**\n",
        "\n",
        "Contributors:\n",
        "* Szymon Pająk\n",
        "* Tomasz Ogiołda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C7wEZL2FNIKD",
      "metadata": {
        "id": "C7wEZL2FNIKD"
      },
      "source": [
        "## Temporary notes\n",
        "\n",
        "### Plan\n",
        "\n",
        "1. Introduction\n",
        "2. Background\n",
        "  - What is RAG? Why is it used?\n",
        "  - What kinds of knowledge representations RAG can use?\n",
        "    - Vectorized embeddings\n",
        "    - Knowledge graph\n",
        "    - Combination of both\n",
        "    - Comparison https://neo4j.com/blog/genai/graphrag-manifesto/\n",
        "\n",
        "  - Explain the dataflow for both knowledge representations (the whole process, from raw data, to querying the knowledge database)\n",
        "3. Demo\n",
        "\n",
        "Tools to be used:\n",
        "\n",
        "- langchain?\n",
        "- neo4j\n",
        "\n",
        "4. Resources\n",
        "\n",
        "- https://neo4j.com/blog/genai/graphrag-manifesto/\n",
        "- https://neo4j.com/blog/developer/langchain4j-graphrag-vector-stores-retrievers/\n",
        "- https://neo4j.com/blog/genai/what-is-retrieval-augmented-generation-rag/\n",
        "- https://neo4j.com/blog/developer/knowledge-graph-rag-application/\n",
        "- https://neo4j.com/blog/news/graphrag-ecosystem-tools/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afb6bd1e",
      "metadata": {
        "id": "afb6bd1e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d4b064c",
      "metadata": {
        "id": "4d4b064c"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "#### Agenda Overview\n",
        "1.  **What is RAG & Why Knowledge Representation Matters**\n",
        "2.  **Common Knowledge Representation Options for RAG:**\n",
        "    *   Vector Embeddings\n",
        "    *   Knowledge Graphs\n",
        "    *   The Hybrid: GraphRAG\n",
        "3.  **Demo:** Building a Knowledge Graph from Spotify Data (using our notebook!)\n",
        "4.  **The GraphRAG Ecosystem & Future**\n",
        "5.  **Conclusion & Q&A**\n",
        "\n",
        "#### Hook\n",
        "*   \"Imagine asking an AI: 'Find me a cheerful song from the 90s by an artist like Queen, but not actually Queen, and something I haven't heard a million times.' How can we build AI that *truly* understands and navigates complex requests over *your* specific data?\"\n",
        "*   \"Large Language Models (LLMs) are powerful, but they don't know everything, especially about recent events or your private information. How can we bridge this gap without constant, costly retraining?\"\n",
        "\n",
        "#### What is RAG?\n",
        "*   **RAG = Retrieval Augmented Generation**\n",
        "*   It's a technique to enhance LLM responses by first retrieving relevant information from an external knowledge base and providing it to the LLM as context.\n",
        "\n",
        "\n",
        "*   **Why RAG?**\n",
        "    *   **Reduces Hallucinations:** LLMs are less likely to make things up if they have relevant facts.\n",
        "    *   **Access to Current Data:** Overcomes knowledge cut-offs.\n",
        "    *   **Domain-Specific Knowledge:** Allows LLMs to answer questions about private or specialized data.\n",
        "    *   **Cost-Effective:** Cheaper than fine-tuning an LLM for every new piece of information.\n",
        "    *   **Verifiability:** Users can often see the source of the information.\n",
        "\n",
        "#### The \"Knowledge\" in RAG\n",
        "*   The effectiveness of RAG heavily depends on **how we store, organize, and retrieve this external knowledge.**\n",
        "*   This is where **Knowledge Representation** comes in. It's about choosing the right structure for your data so the \"Retrieval\" part of RAG is smart and efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11be6d94",
      "metadata": {
        "id": "11be6d94"
      },
      "source": [
        "## Knowledge Representation Options in RAG\n",
        "\n",
        "#### Option 1: Vectorized Embeddings\n",
        "*   **Concept:**\n",
        "    *   Text (documents, sentences, words) is converted into dense numerical vectors (embeddings).\n",
        "    *   These vectors capture semantic meaning – similar concepts have vectors that are close together in \"vector space.\"\n",
        "*   **How it works in RAG:**\n",
        "    1.  Your documents are chunked and each chunk is embedded. These embeddings are stored in a Vector Database.\n",
        "    2.  The user's query is also embedded.\n",
        "    3.  A similarity search (e.g., cosine similarity) is performed to find the document chunks most similar to the query.\n",
        "    4.  These chunks are passed to the LLM as context.\n",
        "*   **Pros:**\n",
        "    *   Excellent for semantic similarity searches (\"find me documents about X\").\n",
        "    *   Relatively mature technology and many tools available.\n",
        "    *   Can be straightforward to implement for basic RAG.\n",
        "*   **Cons:**\n",
        "    *   **\"Bag of words\" problem:** Can lose nuanced relationships and context between pieces of information.\n",
        "    *   **Black Box:** Similarity scores don't always explain *why* something is relevant.\n",
        "    *   Retrieves chunks, which might not be the most efficient or complete context.\n",
        "\n",
        "#### Option 2: Knowledge Graphs (KGs)\n",
        "*   **Concept:**\n",
        "    *   Information is represented as a network of:\n",
        "        *   **Nodes (Entities):** Things, concepts, people (e.g., \"Song,\" \"Artist,\" \"Genre\").\n",
        "        *   **Edges (Relationships):** How entities are connected (e.g., an `Artist` node `PERFORMED` a `Song` node).\n",
        "        *   **Properties:** Attributes of nodes and relationships (e.g., a `Song` node has a `title` property).\n",
        "    *   **(Reference: https://neo4j.com/blog/genai/graphrag-manifesto/, https://neo4j.com/blog/developer/knowledge-graph-rag-application/)**\n",
        "*   **How it works in RAG:**\n",
        "    1.  Your data is modeled and ingested into a Graph Database (like Neo4j).\n",
        "    2.  The user's query can be parsed to identify entities and relationships.\n",
        "    3.  The system can traverse the graph, following relationships to find highly relevant and contextual subgraphs.\n",
        "    4.  This rich, structured context is passed to the LLM.\n",
        "*   **Pros:**\n",
        "    *   **Explicit Relationships:** Captures how information is interconnected, leading to more precise retrieval.\n",
        "    *   **Context-Rich:** Retrieves subgraphs that provide a fuller picture, not just isolated chunks.\n",
        "    *   **Explainable:** The path through the graph can explain *why* information is relevant.\n",
        "    *   **Powerful for Complex Queries:** Can answer questions that require hopping across multiple entities and relationships.\n",
        "*   **Cons:**\n",
        "    *   Can be more complex to design and build the initial graph schema.\n",
        "    *   Requires a different way of thinking about data (connections first).\n",
        "\n",
        "#### Option 3: The Hybrid Approach - GraphRAG\n",
        "*   **Concept: Combining the strengths of KGs and Vector Embeddings.**\n",
        "    *   **(Reference: https://neo4j.com/blog/genai/graphrag-manifesto/, https://neo4j.com/blog/developer/langchain4j-graphrag-vector-stores-retrievers/)**\n",
        "*   **How it can work:**\n",
        "    *   Store rich, structured data in a Knowledge Graph.\n",
        "    *   Generate vector embeddings for text properties within the graph (e.g., song lyrics, album descriptions) or even for nodes/subgraphs.\n",
        "    *   **Use cases:**\n",
        "        1.  Use KG traversal for structured queries and then vector search *within* the retrieved nodes for semantic details.\n",
        "        2.  Use vector search to find initial entry points into the graph, then expand with graph traversal to get more context.\n",
        "        3.  Embed and search for graph patterns or subgraphs.\n",
        "*   **Benefits:**\n",
        "    *   **Best of Both Worlds:** Precise, contextual retrieval from KGs + powerful semantic search from vectors.\n",
        "    *   Handles a wider variety of queries.\n",
        "    *   Leads to more nuanced and accurate information retrieval for the LLM.\n",
        "\n",
        "#### Comparison\n",
        "*   *(Consider creating a small table here or using a visual)*\n",
        "*   | Feature          | Vector Embeddings        | Knowledge Graphs         | GraphRAG (Hybrid)      |\n",
        "*   |------------------|--------------------------|--------------------------|------------------------|\n",
        "*   | **Primary Use**  | Semantic Similarity      | Explicit Relationships   | Both                   |\n",
        "*   | **Context**      | Chunk-based              | Rich, Interconnected     | Very Rich, Multi-faceted |\n",
        "*   | **Explainability**| Low (similarity score)   | High (path traversal)    | High                   |\n",
        "*   | **Query Type**   | Keyword, Semantic        | Complex, Relational      | Broadest Range         |\n",
        "*   | **Data Structure**| Unstructured/Semi-struct.| Highly Structured        | Structured + Embeddings|\n",
        "*   **(More insights in: https://neo4j.com/blog/genai/graphrag-manifesto/)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42ac35f9",
      "metadata": {
        "id": "42ac35f9"
      },
      "source": [
        "## Demo: Building a Knowledge Graph for Music Recommendation RAG\n",
        "\n",
        "#### Goal\n",
        "*   To demonstrate how we can take tabular data (like our Spotify dataset) and transform it into a connected Knowledge Graph in Neo4j.\n",
        "*   This graph will then serve as the \"Knowledge Base\" that a RAG system could use to answer music-related queries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb026af1",
      "metadata": {
        "id": "bb026af1"
      },
      "source": [
        "#### 1. Setup & Initialization\n",
        "*   Importing necessary libraries (Neo4j, Google Generative AI, Pandas).\n",
        "*   Configuring API keys and Neo4j connection details.\n",
        "*   Initializing the embedding model (`text-embedding-004`) and the generative LLM (`gemini-1.5-flash-latest`).\n",
        "    *   *Embedding Model:* Will be used (conceptually in a full RAG) to turn text like lyrics or queries into vectors.\n",
        "    *   *Generative LLM:* Will be used (conceptually) to generate the final natural language response based on retrieved context."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "517d869e",
      "metadata": {
        "id": "517d869e"
      },
      "source": [
        "##### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "_aDL1k1UV39V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_aDL1k1UV39V",
        "outputId": "65872132-b70a-471d-e113-28560788e56e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: neo4j_graphrag[vertexai] in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n",
            "\u001b[33mWARNING: neo4j-graphrag 1.7.0 does not provide the extra 'vertexai'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: fsspec<2025.0.0,>=2024.9.0 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (2024.12.0)\n",
            "Requirement already satisfied: json-repair<0.40.0,>=0.39.1 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (0.39.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (2.11.4)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (5.5.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (6.0.2)\n",
            "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /usr/local/lib/python3.11/dist-packages (from neo4j_graphrag[vertexai]) (6.0.12.20250516)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->neo4j_graphrag[vertexai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->neo4j_graphrag[vertexai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.6.3->neo4j_graphrag[vertexai]) (0.4.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install neo4j neo4j_graphrag[vertexai]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "-xMdMSscVoSt",
      "metadata": {
        "id": "-xMdMSscVoSt"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "NEO4J_URI = userdata.get('NEO4J_URI')\n",
        "NEO4J_PASS = userdata.get('NEO4J_PASS')\n",
        "NEO4J_DB_USER = userdata.get('NEO4J_DB_USER')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1058a1af",
      "metadata": {
        "id": "1058a1af"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "URI = \"neo4j+s://3a2f9088.databases.neo4j.io\"\n",
        "\n",
        "def get_db():\n",
        "  with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_DB_USER, NEO4J_PASS)) as driver:\n",
        "      driver.verify_connectivity()\n",
        "      return driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "500592b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "500592b1",
        "outputId": "07b87f63-0258-44f1-89a9-526d418ed68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/devdope/900k-spotify?dataset_version_number=3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.00G/1.00G [00:25<00:00, 41.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "\n",
        "path = kagglehub.dataset_download(\"devdope/900k-spotify\")\n",
        "songs_csv_path = path + '/spotify_dataset.csv'\n",
        "full_df = pd.read_csv(songs_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sqv4QwNEml4_",
      "metadata": {
        "id": "sqv4QwNEml4_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(9)\n",
        "\n",
        "df = full_df.sample(20000)\n",
        "df = df[['Artist(s)','song', 'text', 'emotion', 'Length', 'Album', 'Genre', 'Energy', 'Popularity', 'Danceability', 'Positiveness']]\n",
        "df[['Energy', 'Popularity', 'Danceability', 'Positiveness']] = df[['Energy', 'Popularity', 'Danceability', 'Positiveness']].astype(int)/100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d2d511",
      "metadata": {
        "id": "94d2d511"
      },
      "source": [
        "#### 2. Data Loading & Preparation\n",
        "*   We're using a Spotify dataset with ~900k songs (we'll sample 20k for the demo).\n",
        "*   Loading into a Pandas DataFrame.\n",
        "*   It includes information like:\n",
        "    *   `Artist(s)`, `song` title, `text` (lyrics), `emotion`, `Length`, `Album`, `Genre`, `Energy`, `Popularity`, `Danceability`, `Positiveness`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "rbJjOkkOsXvO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "rbJjOkkOsXvO",
        "outputId": "29f11186-6194-4d20-ebee-02298112105a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9447ae629b41>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building vector indexes"
      ],
      "metadata": {
        "id": "bHCWSokXTOPU"
      },
      "id": "bHCWSokXTOPU"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vertexai"
      ],
      "metadata": {
        "id": "tDtBaJbjB2KC",
        "outputId": "53d506a6-ff8d-4fec-9c38-29d8e639c856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tDtBaJbjB2KC",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vertexai in /usr/local/lib/python3.11/dist-packages (1.71.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform==1.71.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.29.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.32.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.1.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.11.4)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.16)\n",
            "\u001b[33mWARNING: google-cloud-aiplatform 1.71.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.71.1->google-cloud-aiplatform[all]==1.71.1->vertexai) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GraphRAG"
      ],
      "metadata": {
        "id": "WEEofSXusaTx"
      },
      "id": "WEEofSXusaTx"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import vertexai\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "vertexai.init(\n",
        "    project=\"krr-rag\"\n",
        ")"
      ],
      "metadata": {
        "id": "GMMK9p4fD0LE"
      },
      "id": "GMMK9p4fD0LE",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j_graphrag.retrievers import VectorRetriever, Text2CypherRetriever\n",
        "from neo4j_graphrag.llm import LLMInterface\n",
        "from vertexai.generative_models import GenerationConfig\n",
        "import vertexai.language_models\n",
        "from neo4j_graphrag.generation import GraphRAG\n",
        "from neo4j_graphrag.embeddings import SentenceTransformerEmbeddings\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "class GeminiLLM(LLMInterface):\n",
        "    def __init__(self, model_name: str, generation_config: GenerationConfig = None):\n",
        "        genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "        self.model = genai.GenerativeModel(model_name=model_name)\n",
        "\n",
        "    def invoke(self, input: str) -> str:\n",
        "        response = self.model.generate_content(input)\n",
        "        return response.text\n",
        "\n",
        "    def ainvoke(self, input: str) -> str:\n",
        "        response = self.model.generate_content(input)\n",
        "        return response.text\n",
        "\n",
        "\n",
        "INDEX_NAME = \"index-name\"\n",
        "\n",
        "driver = get_db()\n",
        "\n",
        "embedder = SentenceTransformerEmbeddings(model=\"all-MiniLM-L6-v2\")\n",
        "llm = GeminiLLM(model_name=\"gemini-1.5-flash-001\")\n",
        "\n",
        "vector_retriever = VectorRetriever(driver, INDEX_NAME, embedder)\n",
        "\n",
        "\n",
        "hybrid_rag = GraphRAG(retriever=vector_retriever, llm=llm)\n",
        "\n",
        "neo4j_schema=\"load db schema\"\n",
        "examples = [\n",
        "    \"USER INPUT: 'Which actors starred in the Matrix?' QUERY: MATCH (p:Person)-[:ACTED_IN]->(m:Movie) WHERE m.title = 'The Matrix' RETURN p.name\"\n",
        "]\n",
        "graph_retriever = Text2CypherRetriever(\n",
        "    driver=driver,\n",
        "    llm=llm,\n",
        "    neo4j_schema=neo4j_schema,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "graph_rag = GraphRAG(retriever=graph_retriever, llm=llm)\n",
        "\n",
        "\n",
        "# Query the graph\n",
        "query_text = \"How do I do similarity search in Neo4j?\"\n",
        "response = hybrid_rag.search(query_text=query_text, retriever_config={\"top_k\": 5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2_mRsvrkTN7y",
        "outputId": "12f4baa3-6472-4d59-d9d6-b58e33752f77"
      },
      "id": "2_mRsvrkTN7y",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "No index with name index-name found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j_graphrag/retrievers/base.py\u001b[0m in \u001b[0;36m_fetch_index_infos\u001b[0;34m(self, vector_index_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-503c33fb8723>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeminiLLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-1.5-flash-001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mvector_retriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINDEX_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j_graphrag/retrievers/vector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, driver, index_name, embedder, return_properties, result_formatter, neo4j_database)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_node_property\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_index_infos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_record_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mneo4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRetrieverResultItem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/neo4j_graphrag/retrievers/base.py\u001b[0m in \u001b[0;36m_fetch_index_infos\u001b[0;34m(self, vector_index_name)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_dimension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dimensions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No index with name {self.index_name} found\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRetrieverResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: No index with name index-name found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedder.embed_query(\"How do I do similarity search in Neo4j?\")\n",
        "llm.invoke(\"Hello my friend, tell me sth about you\")"
      ],
      "metadata": {
        "id": "kIIk_6PuFS--",
        "outputId": "872482a9-2132-4429-eec8-6d54a1422a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "id": "kIIk_6PuFS--",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello there! It's nice to meet you. \\n\\nI am a large language model, trained by Google. \\n\\nHere's a little more about me:\\n\\n* **I'm trained on a massive dataset of text and code.** This allows me to generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. \\n* **I'm still under development.** I'm constantly learning and improving, and I'm always excited to see what new things I can do.\\n* **I don't have personal opinions or beliefs.**  I'm designed to be objective and unbiased, and I'll always try to provide you with the most accurate and helpful information.\\n* **I'm not a person.** I'm a computer program, and I don't have feelings or emotions.\\n\\nI'm here to assist you with any questions or tasks you might have. What can I do for you today? 😊 \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def embed_song():\n",
        "\n",
        "\n",
        "def write_song(session, song_id, song_title, lyrics, time_length, energy, popularity, danceability, positiveness):\n",
        "  embedding = embedder.embed_query()\n",
        "\n",
        "  session.run(\"\"\"\n",
        "                MERGE (s:Song {id: $song_id})\n",
        "                ON CREATE SET\n",
        "                    s.title = $song_title,\n",
        "                    s.lyrics = $lyrics,\n",
        "                    s.time_length = $time_length,\n",
        "                    s.energy = $energy,\n",
        "                    s.popularity = $popularity,\n",
        "                    s.danceability = $danceability,\n",
        "                    s.positiveness = $positiveness\n",
        "                ON MATCH SET\n",
        "                    s.title = $song_title,\n",
        "                    s.lyrics = $lyrics,\n",
        "                    s.time_length = $time_length,\n",
        "                    s.energy = $energy,\n",
        "                    s.popularity = $popularity,\n",
        "                    s.danceability = $danceability,\n",
        "                    s.positiveness = $positiveness\n",
        "            \"\"\", song_id=song_id, song_title=song_title, lyrics=lyrics,\n",
        "               time_length=time_length, energy=float(energy) if pd.notna(energy) else None,\n",
        "               popularity=float(popularity) if pd.notna(popularity) else None,\n",
        "               danceability=float(danceability) if pd.notna(danceability) else None,\n",
        "               positiveness=float(positiveness) if pd.notna(positiveness) else None)\n",
        "\n",
        "def process_song_row(row_data, song_id, driver):\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            song_title = row_data['song']\n",
        "            lyrics = str(row_data['text'])\n",
        "            emotion = row_data['emotion']\n",
        "            time_length = row_data['Length']\n",
        "            album_name = row_data['Album']\n",
        "            energy = row_data['Energy']\n",
        "            popularity = row_data['Popularity']\n",
        "            danceability = row_data['Danceability']\n",
        "            positiveness = row_data['Positiveness']\n",
        "\n",
        "            write_song(session, song_id, song_title, lyrics, time_length, energy, popularity, danceability, positiveness)\n",
        "\n",
        "            # Artists\n",
        "            artist_names = []\n",
        "            if pd.notna(row_data['Artist(s)']):\n",
        "                artist_names = [name.strip() for name in str(row_data['Artist(s)']).split(',')]\n",
        "            for artist_name in artist_names:\n",
        "                if artist_name:\n",
        "                    session.run(\"\"\"\n",
        "                        MERGE (ar:Artist {name: $artist_name})\n",
        "                        WITH ar\n",
        "                        MATCH (s:Song {id: $song_id})\n",
        "                        MERGE (ar)-[:PERFORMED]->(s)\n",
        "                    \"\"\", artist_name=artist_name, song_id=song_id)\n",
        "\n",
        "            # Album\n",
        "            if pd.notna(album_name) and album_name.strip():\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (al:Album {name: $album_name})\n",
        "                    WITH al\n",
        "                    MATCH (s:Song {id: $song_id})\n",
        "                    MERGE (s)-[:APPEARS_ON]->(al)\n",
        "                \"\"\", album_name=album_name.strip(), song_id=song_id)\n",
        "\n",
        "            # Genre\n",
        "            genre_names = []\n",
        "            if pd.notna(row_data['Genre']):\n",
        "                genre_names = [name.strip() for name in str(row_data['Genre']).split(',')]\n",
        "            for genre_name in genre_names:\n",
        "                if genre_name:\n",
        "                    session.run(\"\"\"\n",
        "                        MERGE (g:Genre {name: $genre_name})\n",
        "                        WITH g\n",
        "                        MATCH (s:Song {id: $song_id})\n",
        "                        MERGE (s)-[:HAS_GENRE]->(g)\n",
        "                    \"\"\", genre_name=genre_name, song_id=song_id)\n",
        "\n",
        "            # Emotion\n",
        "            if pd.notna(emotion) and emotion.strip():\n",
        "                session.run(\"\"\"\n",
        "                    MERGE (e:Emotion {name: $emotion})\n",
        "                    WITH e\n",
        "                    MATCH (s:Song {id: $song_id})\n",
        "                    MERGE (s)-[:EVOKES]->(e)\n",
        "                \"\"\", emotion=emotion.strip(), song_id=song_id)\n",
        "        driver.close() # Close driver for this task\n",
        "        return f\"Successfully processed song ID: {song_id}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error processing song ID {song_id}: {e}\"\n",
        "\n",
        "\n",
        "def ingest_music_data_multithreaded(df, db_uri, db_user, db_password, max_workers=8):\n",
        "    print(f\"Starting multithreaded data ingestion for {len(df)} songs with {max_workers} workers...\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = []\n",
        "        for idx, row in df.iterrows():\n",
        "            song_id = str(idx) # Ensure ID is a string for consistency\n",
        "            futures.append(executor.submit(process_song_row, row, song_id, db_uri, db_user, db_password))\n",
        "\n",
        "        processed_count = 0\n",
        "        for future in as_completed(futures):\n",
        "            result = future.result()\n",
        "            processed_count += 1\n",
        "            if \"Error\" in result:\n",
        "                print(f\"Error: {result}\")\n",
        "            # else:\n",
        "            #     print(result) # Uncomment if you want to see success messages\n",
        "\n",
        "            if processed_count % 1000 == 0:\n",
        "                print(f\"Processed {processed_count}/{len(df)} songs.\")\n",
        "\n",
        "    print(f\"Finished multithreaded data ingestion. Total processed: {processed_count}/{len(df)} songs.\")\n",
        "\n",
        "def create_constraints():\n",
        "  db = get_db()\n",
        "\n",
        "  with db.session() as session:\n",
        "      session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (s:Song) REQUIRE s.id IS UNIQUE\")\n",
        "      session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (ar:Artist) REQUIRE ar.name IS UNIQUE\")\n",
        "      session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (al:Album) REQUIRE al.name IS UNIQUE\") # Album names might not be unique across artists\n",
        "      session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE\")\n",
        "      session.run(\"CREATE CONSTRAINT IF NOT EXISTS FOR (e:Emotion) REQUIRE e.name IS UNIQUE\")\n",
        "\n",
        "      session.run(\"CREATE INDEX IF NOT EXISTS FOR (s:Song) ON (s.title)\")\n",
        "      session.run(\"CREATE INDEX IF NOT EXISTS FOR (al:Album) ON (al.name)\") # If querying albums by name\n",
        "\n",
        "      print(\"Neo4j constraints and basic indexes for music graph ensured.\")\n",
        "\n",
        "create_constraints()\n",
        "ingest_music_data_multithreaded(df.iloc[0:20], NEO4J_URI, NEO4J_DB_USER, NEO4J_PASS)\n"
      ],
      "metadata": {
        "id": "Zhi5PRgBiEI0"
      },
      "id": "Zhi5PRgBiEI0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E0BNtKmBt5Cy"
      },
      "id": "E0BNtKmBt5Cy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5578dba8",
      "metadata": {
        "id": "5578dba8"
      },
      "source": [
        "#### Why a Knowledge Graph for this data?\n",
        "*   Music is inherently connected!\n",
        "    *   Artists **PERFORM** Songs.\n",
        "    *   Songs **APPEAR_ON** Albums.\n",
        "    *   Songs **HAVE_GENRE** Genre.\n",
        "    *   Songs can **EVOKE** Emotions.\n",
        "    *   Artists can **COLLABORATE_WITH** other Artists (implicitly through songs).\n",
        "*   A KG allows us to model these relationships explicitly, enabling powerful contextual queries that are hard with just tables or vectors alone.\n",
        "    *   \"Find rock songs by artists who also play blues and have collaborated with...\"\n",
        "    *   \"Show me upbeat songs from albums that were popular in a specific year.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c1b76e",
      "metadata": {
        "id": "19c1b76e"
      },
      "source": [
        "#### 3. Neo4j Ingestion: Building the Knowledge Graph!\n",
        "*   **This is the core of transforming tabular data into a connected graph.**\n",
        "*   We use a multithreaded approach for efficiency (`ingest_music_data_multithreaded`).\n",
        "*   **Key function: `process_song_row`** (inside `lKrI12U228B-`)\n",
        "    *   For each song (row in the DataFrame):\n",
        "        *   **`MERGE (s:Song {id: $song_id})`**: Creates a `Song` node if it doesn't exist, or matches it if it does. Sets properties like `title`, `lyrics`, `energy`, etc.\n",
        "        *   **Artists:**\n",
        "            *   Parses artist names.\n",
        "            *   `MERGE (ar:Artist {name: $artist_name})`\n",
        "            *   `MERGE (ar)-[:PERFORMED]->(s)`: **Creates the crucial `PERFORMED` relationship!**\n",
        "        *   **Album:**\n",
        "            *   `MERGE (al:Album {name: $album_name})`\n",
        "            *   `MERGE (s)-[:APPEARS_ON]->(al)`: **Creates the `APPEARS_ON` relationship!**\n",
        "        *   **Genre:**\n",
        "            *   `MERGE (g:Genre {name: $genre_name})`\n",
        "            *   `MERGE (s)-[:HAS_GENRE]->(g)`: **Creates the `HAS_GENRE` relationship!**\n",
        "        *   **Emotion:**\n",
        "            *   `MERGE (e:Emotion {name: $emotion})`\n",
        "            *   `MERGE (s)-[:EVOKES]->(e)`: **Creates the `EVOKES` relationship!**\n",
        "*   **Constraints & Indexes:**\n",
        "    *   `CREATE CONSTRAINT IF NOT EXISTS FOR (s:Song) REQUIRE s.id IS UNIQUE` (and for Artist name, Album name, etc.) - Ensures data integrity and performance.\n",
        "    *   `CREATE INDEX IF NOT EXISTS FOR (s:Song) ON (s.title)` - Speeds up lookups.\n",
        "\n",
        "Here, you see a graph query being triggered. It can optionally include a vector similarity component. You can choose to store your graphs and vectors either separately in two distinct databases, or use a graph database like Neo4j."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d56709d",
      "metadata": {
        "id": "0d56709d"
      },
      "source": [
        "### **TUTAJ JAKIEŚ POMYSŁY NA DALSZĄ CZĘŚĆ DEMO**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81a50825",
      "metadata": {
        "id": "81a50825"
      },
      "source": [
        "## The Broader Ecosystem & Future\n",
        "\n",
        "#### A Rapidly Evolving Field\n",
        "*   Knowledge Representation in RAG, especially GraphRAG, is a hot area of research and development.\n",
        "*   New tools, techniques, and best practices are emerging constantly.\n",
        "*   **(Reference: https://neo4j.com/blog/news/graphrag-ecosystem-tools/)**\n",
        "\n",
        "#### Key Players & Tools in the GraphRAG Ecosystem\n",
        "*   *(Consider a slide with logos here)*\n",
        "*   **Graph Databases:**\n",
        "    *   Neo4j (leading property graph database, excellent for connected data)\n",
        "*   **LLM Orchestration Frameworks:**\n",
        "    *   LangChain (provides modules for building RAG pipelines, including graph components)\n",
        "    *   LlamaIndex (data framework for LLM applications, supports graph structures)\n",
        "*   **Embedding Models & Providers:**\n",
        "    *   OpenAI, Cohere, Google (Vertex AI / Generative AI Studio - like our `text-embedding-004`), Hugging Face Sentence Transformers.\n",
        "*   **LLMs for Generation:**\n",
        "    *   OpenAI (GPT series), Google (Gemini family), Anthropic (Claude), Mistral, Llama models.\n",
        "*   **Vector Databases (for hybrid approaches):**\n",
        "    *   Pinecone, Weaviate, Milvus, Chroma, FAISS (and Neo4j itself has vector indexing capabilities).\n",
        "\n",
        "#### Community & Open Source\n",
        "*   A lot of innovation is driven by the open-source community.\n",
        "*   Many libraries and integrations are available on platforms like GitHub.\n",
        "*   Active discussions, blogs, and research papers are pushing the boundaries.\n",
        "\n",
        "#### Future Trends\n",
        "*   **Automated KG Construction:** LLMs helping to extract entities and relationships from unstructured text to build KGs.\n",
        "*   **More Sophisticated Retrieval Strategies:** Combining graph algorithms, semantic search, and reasoning for even better context.\n",
        "*   **Multi-Modal RAG:** Incorporating knowledge from images, audio, and video into KGs.\n",
        "*   **Evaluation Frameworks:** Better ways to measure the quality of retrieval and generation in RAG systems."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc717b1",
      "metadata": {
        "id": "fdc717b1"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "#### Recap: Key Takeaways\n",
        "1.  **RAG is Essential:** It makes LLMs more factual, current, and domain-aware by connecting them to external knowledge.\n",
        "2.  **Knowledge Representation is CRUCIAL:**\n",
        "    *   **Vector Embeddings:** Great for semantic similarity over large text corpora.\n",
        "    *   **Knowledge Graphs:** Excel at representing explicit relationships and providing rich, structured context. Ideal for complex queries.\n",
        "3.  **GraphRAG (Hybrid) is Powerful:** Combining KGs with vector search offers the most robust and nuanced approach to knowledge retrieval.\n",
        "4.  **Practical Application:** As shown in our demo, we can transform raw data into a connected Knowledge Graph (e.g., in Neo4j) to serve as the backbone for an advanced RAG system.\n",
        "\n",
        "#### Future Outlook\n",
        "*   The synergy between LLMs and structured knowledge (like KGs) will continue to drive innovation.\n",
        "*   Expect more intelligent, context-aware, and explainable AI systems powered by these techniques.\n",
        "\n",
        "#### Sources\n",
        "\n",
        "1.  GraphRAG Manifesto: [https://neo4j.com/blog/genai/graphrag-manifesto/](https://neo4j.com/blog/genai/graphrag-manifesto/)\n",
        "2.  Langchain4j & GraphRAG: [https://neo4j.com/blog/developer/langchain4j-graphrag-vector-stores-retrievers/](https://neo4j.com/blog/developer/langchain4j-graphrag-vector-stores-retrievers/)\n",
        "3.  What is RAG?: [https://neo4j.com/blog/genai/what-is-retrieval-augmented-generation-rag/](https://neo4j.com/blog/genai/what-is-retrieval-augmented-generation-rag/)\n",
        "4.  KG RAG Application: [https://neo4j.com/blog/developer/knowledge-graph-rag-application/](https://neo4j.com/blog/developer/knowledge-graph-rag-application/)\n",
        "5.  GraphRAG Ecosystem: [https://neo4j.com/blog/news/graphrag-ecosystem-tools/](https://neo4j.com/blog/news/graphrag-ecosystem-tools/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "KrakenV2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}